{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "# from text_functions_solutions import clean_tokenize, get_patterns\n",
    "from pathlib import Path\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data location\n",
    "data_location = Path(\"../datasets\")\n",
    "\n",
    "# constants\n",
    "PUNCT_SET = set(punctuation)\n",
    "SW_ENG = stopwords.words(\"english\")\n",
    "WHITESPACE_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "\n",
    "# helper functions\n",
    "def tokenize_on_ws(text):\n",
    "    return WHITESPACE_RE.split(text)\n",
    "\n",
    "\n",
    "def remove_punct(tokens, punct_set=PUNCT_SET):\n",
    "    cleaned = []\n",
    "    for token in tokens:\n",
    "        tok = \"\".join([ch for ch in token if ch not in punct_set])\n",
    "        if tok:\n",
    "            cleaned.append(tok)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def is_alpha(tokens):\n",
    "    return [token for token in tokens if token.isalpha()]\n",
    "\n",
    "\n",
    "def remove_stopwords(tokens, sw=SW_ENG):\n",
    "    tokens = [token for token in tokens if token.lower() not in sw]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def lowercase(tokens):\n",
    "    return [token.lower() for token in tokens]\n",
    "\n",
    "\n",
    "def join_to_string(tokens):\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "def run_pipeline(text, pipeline):\n",
    "    tokens = str(text)\n",
    "\n",
    "    for transform in pipeline:\n",
    "        tokens = transform(tokens)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(data_location / \"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" exercise. First, we'll pull in the text\n",
    "for each party and prepare it for use in Naive Bayes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill the above list up with items that are themselves lists. The\n",
    "# sublists will have two elements. The first element in the sublist\n",
    "# should be the speech in a single string. The second element\n",
    "# of the sublist should be the party.\n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "    # -- your query here, pull only 2020 data.\n",
    "    # -- Remove the party \"Other\".\n",
    "    \"\"\"    \n",
    "    SELECT text, party \n",
    "    FROM conventions \n",
    "    WHERE party != 'Other';\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "for row in query_results:\n",
    "    # store the results in convention_data\n",
    "    convention_data.append([row[0], row[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's a best practice to close up your DB connection when you're done\n",
    "convention_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['An oath.', 'Republican'],\n",
       " ['If we do not get meaningful legislation out of this Congress, we will march through the South, through the streets of Jackson, through the streets of Danville, through the streets of Cambridge, through the streets of Birmingham. James M. Lawson Jr.: ( 40:34 )  I think he is the singular figure that has tried to carry out the work of our nonviolent campaigns into the halls of Congress.',\n",
       "  'Democratic'],\n",
       " ['Well, I may be kidding myself, but I think the people are ready. I think people are ready, we just got to keep pushing. We can’t let up. But thank you for what you’re doing. I really appreciate it. Thanks for joining me.',\n",
       "  'Democratic'],\n",
       " ['Questions about money he made from foreign business dealings while his father was vice president.',\n",
       "  'Republican'],\n",
       " ['Is to do nothing substantive to reduce it. To release prisoners as many, and as soon as possible, and to go to war with the police, the only group with the capability to protect your citizens. It is clear that a vote for Biden and the Democrats creates the risk that you will bring this lawlessness to your city, to your town, to your suburb. There is no question that this awesome job of restoring safety for our people cannot be done from your basement Joe. There’s also no question that President Trump will fight with all his strengths to preserve the American system of government and our way of life-',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll be useful for us to have a large sample size than 2020 affords, since those speeches tend to be long and contiguous. Let's make a new list-of-lists called `conv_sent_data`. Instead of each first entry in the sublists being an entire speech, make each first entry just a sentence from the speech. Feel free to use NLTK's `sent_tokenize` [function](https://www.nltk.org/api/nltk.tokenize.sent_tokenize.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/junc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/junc/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "conv_sent_data = []\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "for speech, party in convention_data:\n",
    "    sentences = sent_tokenize(speech)\n",
    "    conv_sent_data.append([sentences[0], party])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's look at some random entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Yes, they are?', 'Republican'],\n",
       " ['California, home to our next Vice President Kamala Harris, casts 231 votes for Bernie Sanders and 263 votes for our next President, Joe Biden.',\n",
       "  'Democratic'],\n",
       " ['We simply cannot endure a Biden-induced recession.', 'Republican'],\n",
       " ['I’m Sean Parnell, and it is an honor to be here.', 'Republican'],\n",
       " ['If I apply this test to Joe Biden, I can’t say yes to any of these three questions.',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(conv_sent_data, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for our final cleaning before modeling. Go through `conv_sent_data` and take the following steps:\n",
    "\n",
    "1. Tokenize on whitespace\n",
    "1. Remove punctuation\n",
    "1. Remove tokens that fail the `isalpha` test\n",
    "1. Remove stopwords\n",
    "1. Casefold to lowercase\n",
    "1. Join the remaining tokens into a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('middle east iran threatened president approved strike killed iranian terrorist qasem soleimani',\n",
       "  'Republican'),\n",
       " ('welcome', 'Democratic'),\n",
       " ('proudly displayed', 'Republican'),\n",
       " ('lot democrats support president disgusted old party old party become',\n",
       "  'Republican'),\n",
       " ('yes', 'Democratic')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_pipeline = [\n",
    "    tokenize_on_ws,\n",
    "    remove_punct,\n",
    "    is_alpha,\n",
    "    remove_stopwords,\n",
    "    lowercase,\n",
    "    join_to_string,\n",
    "]\n",
    "\n",
    "clean_conv_sent_data = []  # list of tuples (sentence, party), with sentence cleaned\n",
    "\n",
    "for idx, sent_party in enumerate(conv_sent_data):\n",
    "    # pass  # your code here\n",
    "    # print(idx, sent_party[0], \"\\n\")\n",
    "    cleaned = run_pipeline(sent_party[0], speech_pipeline)\n",
    "    # print(idx, cleaned)\n",
    "    if cleaned:\n",
    "        clean_conv_sent_data.append((cleaned, sent_party[1]))\n",
    "\n",
    "random.choices(clean_conv_sent_data, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, let's make our function to turn these into features. First we need to build our list of candidate words. I started my exploration at a cutoff of 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 628 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in clean_conv_sent_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items():\n",
    "    if count > word_cutoff:\n",
    "        feature_words.add(word)\n",
    "\n",
    "print(\n",
    "    f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text, fw):\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "    feature words.\n",
    "\n",
    "    Args:\n",
    "         * text: a piece of text in a continuous string. Assumes\n",
    "         text has been cleaned and case folded.\n",
    "         * fw: the *feature words* that we're considering. A word\n",
    "         in `text` must be in fw in order to be returned. This\n",
    "         prevents us from considering very rarely occurring words.\n",
    "\n",
    "    Returns:\n",
    "         A dictionary with the words in `text` that appear in `fw`.\n",
    "         Words are only counted once.\n",
    "         If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "         then this would return a dictionary of\n",
    "         {'quick' : True,\n",
    "          'fox' :    True}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Your code here\n",
    "\n",
    "    ret_dict = dict()\n",
    "\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(feature_words) > 0\n",
    "assert conv_features(\"obama was the president\", feature_words) == {\n",
    "    \"obama\": True,\n",
    "    \"president\": True,\n",
    "}\n",
    "assert conv_features(\"some people in america are citizens\", feature_words) == {\n",
    "    \"people\": True,\n",
    "    \"america\": True,\n",
    "    \"citizens\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [\n",
    "    (conv_features(text, feature_words), party) for (text, party) in convention_data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "_Your observations to come._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and\n",
    "is unindexed, so the query takes a minute or two to run on my machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_twitter_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "    \"\"\"\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "results = list(results)  # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet, party in tweet_data_sample:\n",
    "    estimated_party = \"??\"  # you need to fill this in.\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "\n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party.\n",
    "# first key is actual, second is estimated\n",
    "parties = [\"Republican\", \"Democratic\"]\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties:\n",
    "    for p1 in parties:\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data):\n",
    "    tweet, party = tp\n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them.\n",
    "\n",
    "    # get the estimated party\n",
    "    estimated_party = \"Gotta fill this in\"\n",
    "\n",
    "    results[party][estimated_party] += 1\n",
    "\n",
    "    if idx > num_to_score:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "_Write a little about what you see in the results_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ads509",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
