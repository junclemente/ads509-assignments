{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "# from text_functions_solutions import clean_tokenize, get_patterns\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Preprocessing Pipeline Setup\n",
    "\n",
    "The following are the helper functions for the text preprocessing pipeline. The pipeline includes the following transformations:\n",
    "\n",
    "1. **Tokenize on whitespace** – split sentences into tokens based on spaces.\n",
    "2. **Remove punctuation** – strip out punctuation marks from tokens.\n",
    "3. **Keep only alphabetic tokens** – discard numbers, symbols, and mixed tokens.\n",
    "4. **Remove stopwords** – filter out common words (e.g., \"the\", \"and\") that carry little meaning.\n",
    "5. **Lowercase conversion** – normalize all words to lowercase.\n",
    "6. **Join back to string** – reconstruct the cleaned tokens into a single string.\n",
    "\n",
    "The `run_pipeline()` function executes these steps in sequence for any given sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data location\n",
    "data_location = Path(\"../datasets\")\n",
    "\n",
    "# constants\n",
    "PUNCT_SET = set(punctuation)\n",
    "TW_PUNCT_SET = PUNCT_SET - {\"#\", \"@\"}\n",
    "SW_ENG = stopwords.words(\"english\")\n",
    "WHITESPACE_RE = re.compile(r\"\\s+\")\n",
    "TWEET_RE = re.compile(\"(^b['\\\"])(.*)\")\n",
    "\n",
    "\n",
    "# helper functions\n",
    "def tokenize_on_ws(text):\n",
    "    return WHITESPACE_RE.split(text)\n",
    "\n",
    "\n",
    "def remove_punct(tokens, punct_set=PUNCT_SET):\n",
    "    cleaned = []\n",
    "    for token in tokens:\n",
    "        tok = \"\".join([ch for ch in token if ch not in punct_set])\n",
    "        if tok:\n",
    "            cleaned.append(tok)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def is_alpha(tokens):\n",
    "    return [token for token in tokens if token.isalpha()]\n",
    "\n",
    "\n",
    "def remove_stopwords(tokens, sw=SW_ENG):\n",
    "    tokens = [token for token in tokens if token.lower() not in sw]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def lowercase(tokens):\n",
    "    return [token.lower() for token in tokens]\n",
    "\n",
    "\n",
    "def join_to_string(tokens):\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "def clean_tweet(text):\n",
    "    return TWEET_RE.match(text).group(2)\n",
    "\n",
    "\n",
    "def run_pipeline(text, pipeline):\n",
    "    tokens = str(text)\n",
    "\n",
    "    for transform in pipeline:\n",
    "        tokens = transform(tokens)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(data_location / \"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" exercise. First, we'll pull in the text\n",
    "for each party and prepare it for use in Naive Bayes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill the above list up with items that are themselves lists. The\n",
    "# sublists will have two elements. The first element in the sublist\n",
    "# should be the speech in a single string. The second element\n",
    "# of the sublist should be the party.\n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "    # -- your query here, pull only 2020 data.\n",
    "    # -- Remove the party \"Other\".\n",
    "    \"\"\"    \n",
    "    SELECT text, party \n",
    "    FROM conventions \n",
    "    WHERE party != 'Other';\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "for row in query_results:\n",
    "    # store the results in convention_data\n",
    "    convention_data.append([row[0], row[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's a best practice to close up your DB connection when you're done\n",
    "convention_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value counts of Democractic vs Republican Speeches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Democratic Speeches: 1551 (61.04%)\n",
      "Rebuplican Speeches: 990 (38.96%)\n",
      "2541\n"
     ]
    }
   ],
   "source": [
    "party_counts = Counter(row[1] for row in convention_data)\n",
    "\n",
    "total = party_counts[\"Democratic\"] + party_counts[\"Republican\"]\n",
    "dem = party_counts[\"Democratic\"] / total\n",
    "rep = party_counts[\"Republican\"] / total\n",
    "print(f'Democratic Speeches: {party_counts[\"Democratic\"]} ({dem * 100:.2f}%)')\n",
    "print(f'Rebuplican Speeches: {party_counts[\"Republican\"]} ({rep * 100:.2f}%)')\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Indiana.', 'Republican'],\n",
       " ['We’ve brought together voices from every part of America.', 'Democratic'],\n",
       " ['Joe has always cared about military families. They’ve been through so much. When I went to Iraq, one of the generals said, ” I want to share the story with you.” In his daughter’s class, it was a Christmas program and they were playing the Ave Maria. And one of the little girls burst into tears and the teacher ran over and said, “What’s the matter? What’s the matter?” And she said, “That’s the song they played at my daddy’s funeral. He died in the war.” The teacher had no idea that that little girl’s father had fought in the war and had died. And that night I said to my staff, I’m a teacher, we can do better. We’ve got to do better to help our military kids.',\n",
       "  'Democratic'],\n",
       " ['The Bidens have a track record of helping military families. And we’ve seen it with their work that they’ve done with joining forces, and how they were able to rally a country behind us.',\n",
       "  'Democratic'],\n",
       " ['Joe Biden wants to build an economy far better suited to our changing world. Better for young people. Better for families working and raising their kids. Better for people who lost jobs and need new ones. Better for farmers tired of being collateral damage in trade wars. Better for workers caring for the sick, elderly, and people with disabilities. Better because of a living wage and access to affordable higher education and healthcare, including prescription drugs, and to childcare, a secure retirement, and for the first time, paid family and medical leave.',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll be useful for us to have a large sample size than 2020 affords, since those speeches tend to be long and contiguous. Let's make a new list-of-lists called `conv_sent_data`. Instead of each first entry in the sublists being an entire speech, make each first entry just a sentence from the speech. Feel free to use NLTK's `sent_tokenize` [function](https://www.nltk.org/api/nltk.tokenize.sent_tokenize.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/junc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/junc/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "conv_sent_data = []\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "for speech, party in convention_data:\n",
    "    sentences = sent_tokenize(speech)\n",
    "    conv_sent_data.append([sentences[0], party])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's look at some random entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The great John Lewis would often quote the old African proverb, “When pray, move your feet,” and then challenge us to do just that.',\n",
       "  'Democratic'],\n",
       " ['He brought together law enforcement, prosecutors, advocate, and survivors.',\n",
       "  'Democratic'],\n",
       " ['Refusing to be told who makes decisions about her body or anyone else’s.',\n",
       "  'Democratic'],\n",
       " ['We are a people in a quandary about the present.', 'Democratic'],\n",
       " ['State or sovereignty.', 'Republican']]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(conv_sent_data, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for our final cleaning before modeling. Go through `conv_sent_data` and take the following steps:\n",
    "\n",
    "1. Tokenize on whitespace\n",
    "1. Remove punctuation\n",
    "1. Remove tokens that fail the `isalpha` test\n",
    "1. Remove stopwords\n",
    "1. Casefold to lowercase\n",
    "1. Join the remaining tokens into a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time recognize childcare part basic infrastructure nation', 'Democratic'),\n",
       " ('washington dc welcome republican national convention', 'Republican'),\n",
       " ('name stacia brightmon', 'Republican'),\n",
       " ('madeline lauf founder begin health nutritional company', 'Republican'),\n",
       " ('missouri', 'Republican')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup pipeline\n",
    "speech_pipeline = [\n",
    "    tokenize_on_ws,\n",
    "    remove_punct,\n",
    "    is_alpha,\n",
    "    remove_stopwords,\n",
    "    lowercase,\n",
    "    join_to_string,\n",
    "]\n",
    "\n",
    "clean_conv_sent_data = []  # list of tuples (sentence, party), with sentence cleaned\n",
    "\n",
    "for idx, sent_party in enumerate(conv_sent_data):\n",
    "    cleaned = run_pipeline(sent_party[0], speech_pipeline)\n",
    "    if cleaned:\n",
    "        clean_conv_sent_data.append((cleaned, sent_party[1]))\n",
    "\n",
    "random.choices(clean_conv_sent_data, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, let's make our function to turn these into features. First we need to build our list of candidate words. I started my exploration at a cutoff of 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 628 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in clean_conv_sent_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items():\n",
    "    if count > word_cutoff:\n",
    "        feature_words.add(word)\n",
    "\n",
    "print(\n",
    "    f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text, fw):\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "    feature words.\n",
    "\n",
    "    Args:\n",
    "         * text: a piece of text in a continuous string. Assumes\n",
    "         text has been cleaned and case folded.\n",
    "         * fw: the *feature words* that we're considering. A word\n",
    "         in `text` must be in fw in order to be returned. This\n",
    "         prevents us from considering very rarely occurring words.\n",
    "\n",
    "    Returns:\n",
    "         A dictionary with the words in `text` that appear in `fw`.\n",
    "         Words are only counted once.\n",
    "         If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "         then this would return a dictionary of\n",
    "         {'quick' : True,\n",
    "          'fox' :    True}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ret_dict = dict()\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if word in fw:\n",
    "            ret_dict[word] = True\n",
    "\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(feature_words) > 0\n",
    "assert conv_features(\"obama was the president\", feature_words) == {\n",
    "    \"obama\": True,\n",
    "    \"president\": True,\n",
    "}\n",
    "assert conv_features(\"some people in america are citizens\", feature_words) == {\n",
    "    \"people\": True,\n",
    "    \"america\": True,\n",
    "    \"citizens\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [\n",
    "    (conv_features(text, feature_words), party) for (text, party) in convention_data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.494\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             enforcement = True           Republ : Democr =     27.5 : 1.0\n",
      "                   votes = True           Democr : Republ =     21.6 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.3 : 1.0\n",
      "                   media = True           Republ : Democr =     15.9 : 1.0\n",
      "              appreciate = True           Republ : Democr =     14.0 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.3 : 1.0\n",
      "                 special = True           Republ : Democr =     10.3 : 1.0\n",
      "                   local = True           Republ : Democr =      9.9 : 1.0\n",
      "                   elect = True           Democr : Republ =      9.6 : 1.0\n",
      "                    land = True           Republ : Democr =      8.9 : 1.0\n",
      "                  cities = True           Republ : Democr =      8.4 : 1.0\n",
      "                citizens = True           Republ : Democr =      8.4 : 1.0\n",
      "                    flag = True           Republ : Democr =      8.4 : 1.0\n",
      "                greatest = True           Republ : Democr =      8.4 : 1.0\n",
      "                   clean = True           Democr : Republ =      7.9 : 1.0\n",
      "                 freedom = True           Republ : Democr =      7.8 : 1.0\n",
      "                     law = True           Republ : Democr =      7.8 : 1.0\n",
      "                  senior = True           Republ : Democr =      7.8 : 1.0\n",
      "                  record = True           Republ : Democr =      7.3 : 1.0\n",
      "                officers = True           Republ : Democr =      7.2 : 1.0\n",
      "                grateful = True           Republ : Democr =      6.9 : 1.0\n",
      "                    grew = True           Republ : Democr =      6.9 : 1.0\n",
      "                  heroes = True           Republ : Democr =      6.8 : 1.0\n",
      "                  border = True           Republ : Democr =      6.7 : 1.0\n",
      "                    race = True           Republ : Democr =      6.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "Out of all the most informative feature words, 21 of the 25 words are\n",
    "dominated by the Republican party. This is an interesting point because the\n",
    "original dataset was dominantly speeches made by Democrats with 61% and only\n",
    "39% for Republican speeches. This shows that speech patterns by Republicans\n",
    "are very structured and use the same words. They are very aligned within their\n",
    "messaging. In contrast, the Democratic speeches are not as\n",
    "aligned and therefore the parties messaging and focus may not be as clear.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and\n",
    "is unindexed, so the query takes a minute or two to run on my machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(data_location / \"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "    \"\"\"\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "results = list(results)  # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "twitter_pipeline = [\n",
    "    clean_tweet,\n",
    "    tokenize_on_ws,\n",
    "    partial(remove_punct, punct_set=TW_PUNCT_SET),\n",
    "    is_alpha,\n",
    "    lowercase,\n",
    "    join_to_string,\n",
    "]\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "for result in results:\n",
    "    cleaned = run_pipeline(result[2], twitter_pipeline)\n",
    "    if cleaned:\n",
    "        tweet_data.append((cleaned, result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value counts of Democratic vs Republican Tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Democratic Tweets: 710814 (58.91%)\n",
      "Republican Tweets: 495800 (41.09%)\n"
     ]
    }
   ],
   "source": [
    "twparty_counts = Counter(row[1] for row in tweet_data)\n",
    "\n",
    "total = twparty_counts[\"Democratic\"] + twparty_counts[\"Republican\"]\n",
    "dem = twparty_counts[\"Democratic\"] / total\n",
    "rep = twparty_counts[\"Republican\"] / total\n",
    "print(f\"Democratic Tweets: {twparty_counts['Democratic']} ({dem * 100:.2f}%)\")\n",
    "print(f\"Republican Tweets: {twparty_counts['Republican']} ({rep * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: rt and got you covered registration candidate how\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: follow us on twitter like us on facebook too\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: to my jewish friends and family around the world have an easy fast may you be sealed in the book of life gmar hatima tova and dont forget to say a quick prayer for our fellows in the whose minds may not be entirely on tonight gd bless\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: rt congressional candidate abigail spanberger had a brilliant comeback to her gop opponent constantly calling her nancy\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: thank you and yes only what is right for the american people\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: i think whats hes trying to say is he thinks i did a good job on cnn hes just playing hard to get\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: lies\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: rt just two weeks ago ted cruz celebrated gun violence with the nra what should texas do with him ask\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: trumps executive orders are rooted in an unamerican hostility toward immigrant\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: hambardzoum avagyannkhachatour avagyannhovsep sarkissiannkhatchadour jingiriannalex petrosyannsarkis\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample:\n",
    "    features = conv_features(tweet, feature_words)\n",
    "    estimated_party = classifier.classify(features)\n",
    "\n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party.\n",
    "# first key is actual, second is estimated\n",
    "parties = [\"Republican\", \"Democratic\"]\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties:\n",
    "    for p1 in parties:\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data):\n",
    "    tweet, party = tp\n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them.\n",
    "    features = conv_features(tweet, feature_words)\n",
    "    # get the estimated party\n",
    "    estimated_party = classifier.classify(features)\n",
    "    # estimated_party = \"Gotta fill this in\"\n",
    "\n",
    "    results[party][estimated_party] += 1\n",
    "\n",
    "    if idx > num_to_score:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Pred Rep  Pred Dem\n",
      "Actual Rep      2965      1074\n",
      "Act Dem         4559      1404\n",
      "\n",
      "Accuracy: 43.7%\n",
      "Precision: 39.4%\n",
      "Recall: 73.4%\n",
      "F1: 51.3%\n"
     ]
    }
   ],
   "source": [
    "tp_rep = results[\"Republican\"][\"Republican\"]\n",
    "fn_rep = results[\"Republican\"][\"Democratic\"]\n",
    "fp_rep = results[\"Democratic\"][\"Republican\"]\n",
    "tn_rep = results[\"Democratic\"][\"Democratic\"]\n",
    "\n",
    "accuracy = (tp_rep + tn_rep) / (tp_rep + fn_rep + fp_rep + tn_rep)\n",
    "precision = tp_rep / (tp_rep + fp_rep)\n",
    "recall = tp_rep / (tp_rep + fn_rep)\n",
    "f1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "cm = pd.DataFrame(\n",
    "    [[tp_rep, fn_rep], [fp_rep, tn_rep]],\n",
    "    index=[\"Actual Rep\", \"Act Dem\"],\n",
    "    columns=[\"Pred Rep\", \"Pred Dem\"],\n",
    ")\n",
    "\n",
    "print(cm)\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.1f}%\")\n",
    "print(f\"Precision: {precision * 100:.1f}%\")\n",
    "print(f\"Recall: {recall * 100:.1f}%\")\n",
    "print(f\"F1: {f1 * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "There is a huge imbalance between the targets with 59% Democratic tweets vs 41% Republican tweets. Yet, the model is able to accurately predict the tweet as Republican about two times more than Democratic tweets. With that said, the accuracy of the model is less than random chance at 44%. The precision of the models shows a lot of false positives for the target class of \"Republican\". The recall tells us that the model is good at identifying the target class but also means a lot of misclassifying \"Democrats\".\n",
    "\n",
    "Overall, the model is over-predicting Republican. As in the speeches, Republican speeches use more targeted words while Democratic speeches use more diverse language. Even with the class imbalance, the feature words in Republican speeches, and tweets for that matter, overshadow the feature words of Democratic speeches and tweets.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ads509",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
