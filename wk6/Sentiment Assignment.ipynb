{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f79baf9",
   "metadata": {},
   "source": [
    "# ADS 509 Sentiment Assignment\n",
    "\n",
    "This notebook holds the Sentiment Assignment for Module 6 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required.\n",
    "\n",
    "In a previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we apply sentiment analysis to those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8e2e1",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it.\n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link.\n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell.\n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. _Make sure to answer every question marked with a `Q:` for full credit._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d096b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b555ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "923b5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "data_location = Path(\"../datasets\")\n",
    "\n",
    "# These subfolders should still work if you correctly stored the\n",
    "# data from the Module 1 assignment\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\"\n",
    "\n",
    "positive_words_file = \"positive-words.txt\"\n",
    "negative_words_file = \"negative-words.txt\"\n",
    "tidy_text_file = \"tidytext_sentiments.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bf93e",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A Pandas data frame would work equally well.\n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d70801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the lyrics data\n",
    "\n",
    "# create path to lyrics\n",
    "lyrics_path = os.path.join(data_location, lyrics_folder)\n",
    "\n",
    "# get list of artists in lyrics folder\n",
    "artists = os.listdir(lyrics_path)\n",
    "\n",
    "# initialize rows list for dataframe\n",
    "rows = []\n",
    "\n",
    "for artist in artists:\n",
    "    # create path to song lyrics\n",
    "    song_lyrics_path = os.path.join(lyrics_path, artist)\n",
    "\n",
    "    # iterate through all song files in the directory\n",
    "    for songs in os.listdir(song_lyrics_path):\n",
    "        # create path to song file\n",
    "        file_path = os.path.join(song_lyrics_path, songs)\n",
    "\n",
    "        # read txt file to lyrics var\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # create regex to capture title between double quotes\n",
    "        match = re.match(r'^\"(.*)\"$', lines[0].strip())\n",
    "        if match:\n",
    "            song_title = match.group(1)\n",
    "        else:\n",
    "            # fallback to first line as title\n",
    "            song_title = lines[0].strip()\n",
    "\n",
    "        # save rest of lines to lyrics\n",
    "        lyrics = \"\".join(lines[1:]).strip()\n",
    "\n",
    "        rows.append({\"artist\": artist, \"song_title\": song_title, \"lyrics\": lyrics})\n",
    "\n",
    "# create dataframe from rows var\n",
    "df_lyrics = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "debcac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the twitter data\n",
    "twitter_path = os.path.join(data_location, twitter_folder)\n",
    "\n",
    "twitter_files = os.listdir(twitter_path)\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Regex101 was used to create the regex\n",
    "# ChatGPT was used to help create the syntax to make the regex useable with\n",
    "# Python\n",
    "LINE_RE = re.compile(\n",
    "    r\"^(?P<screen_name>[^\\t]*)\\t\"\n",
    "    r\"(?P<name>[^\\t]*)\\t\"\n",
    "    r\"(?P<id>\\d+)\\t\"\n",
    "    r\"(?P<location>[^\\t]*)\\t\"\n",
    "    r\"(?P<followers_count>\\d+)\\t\"\n",
    "    r\"(?P<friends_count>\\d+)\\t\"\n",
    "    r\"(?P<description>.*)$\"\n",
    ")\n",
    "\n",
    "\n",
    "for file in twitter_files:\n",
    "    # filter for data file that has description column\n",
    "    if \"_data.txt\" in file and file != \".DS_Store\":\n",
    "        # save robynkonichiwa as robyn\n",
    "        artist = file.split(\"_\")[0].replace(\"konichiwa\", \"\")\n",
    "        file_path = os.path.join(twitter_path, file)\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            # skip header row by assigning to `_`\n",
    "            _ = f.readline()\n",
    "            # iterate through remaining lines\n",
    "            for line in f:\n",
    "                line = line.rstrip(\"\\n\")\n",
    "                m = LINE_RE.match(line)\n",
    "                if m:\n",
    "                    desc = m.group(\"description\")\n",
    "                    # only append if desc is not blank\n",
    "                    if desc:\n",
    "                        rows.append({\"artist\": artist, \"description\": desc})\n",
    "\n",
    "\n",
    "df_twitter = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa7dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sentiment_value(word, current_value, new_value, verbose=False):\n",
    "    \"\"\"\n",
    "    Resolve a word's sentiment score when encountering potential conflicts.\n",
    "\n",
    "    Given an existing sentiment score (`current_value`) and a proposed new\n",
    "    score (`new_value`) for the same word, this function applies the\n",
    "    following rules:\n",
    "\n",
    "    1) If the current value is already 0 (previously marked conflicting),\n",
    "       keep it as 0.\n",
    "    2) If the current value differs from the new value (e.g., +1 vs -1),\n",
    "       mark as conflicting by setting the score to 0.\n",
    "    3) Otherwise (values match), keep the new value.\n",
    "\n",
    "    When `verbose=True`, a human-readable message describing the decision\n",
    "    is printed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    word : str\n",
    "        The token/term being evaluated.\n",
    "    current_value : int\n",
    "        The word's existing sentiment score in the dictionary. Expected\n",
    "        values are typically {-1, 0, 1}, where 0 denotes a conflict found\n",
    "        earlier.\n",
    "    new_value : int\n",
    "        The proposed sentiment score for the word (usually -1 or 1).\n",
    "    verbose : bool, optional\n",
    "        If True, prints a message describing the resolution. Defaults to False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The resolved sentiment score for the word:\n",
    "        - 0 if a conflict is detected or already present,\n",
    "        - `new_value` if it matches `current_value`,\n",
    "        - `current_value` if it is already 0.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Use this helper during dictionary construction to ensure that once a\n",
    "      word is marked as conflicting (0), it remains 0 on subsequent passes.\n",
    "    - ChatGPT assisted in creating this docstring.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> check_sentiment_value(\"happy\", 1, 1)\n",
    "    1\n",
    "    >>> check_sentiment_value(\"sick\", 1, -1)\n",
    "    0\n",
    "    >>> check_sentiment_value(\"wicked\", 0, 1)\n",
    "    0\n",
    "    \"\"\"\n",
    "    message = \"\"\n",
    "    score_value = None\n",
    "    if current_value == 0:\n",
    "        message = \"Conflicting sentiment value already determined!\"\n",
    "        score_value = current_value\n",
    "    elif current_value != new_value:\n",
    "        message = f\"Conflict: {current_value} vs {new_value}.\"\n",
    "        score_value = 0\n",
    "    else:\n",
    "        message = \"Exists but no conflict in sentiment value.\"\n",
    "        score_value = new_value\n",
    "\n",
    "    if verbose:\n",
    "        message_0 = f\"{word}: \"\n",
    "        message_value = f\"Value set to {score_value}.\"\n",
    "        print(message_0 + message + message_value)\n",
    "\n",
    "    return score_value\n",
    "\n",
    "\n",
    "def create_scoring_dict(dictionary_name, text_file_of_words, base_value, verbose=False):\n",
    "    \"\"\"\n",
    "    Populate a sentiment scoring dictionary from a plain-text word list.\n",
    "\n",
    "    Reads a text file (one word per line) and inserts each cleaned, lowercased\n",
    "    word into `dictionary_name` with the given `base_value` (e.g., +1 for a\n",
    "    positive lexicon, -1 for a negative lexicon). Lines starting with ';'\n",
    "    are treated as comments and skipped. If a word already exists in the\n",
    "    dictionary, the final score is resolved via `check_sentiment_value`\n",
    "    to handle conflicts (e.g., a word appearing in both positive and negative lists);\n",
    "    once a word has been marked conflicting (score 0), it remains 0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dictionary_name : dict[str, int]\n",
    "        The mapping of words to sentiment scores. Modified in place.\n",
    "        Typical scores are {-1, 0, 1}.\n",
    "    text_file_of_words : str\n",
    "        Path to a newline-delimited word list. Each non-empty, non-comment\n",
    "        line should contain a single token.\n",
    "    base_value : int\n",
    "        The base sentiment score to assign to each word from this file\n",
    "        (commonly +1 for positive or -1 for negative).\n",
    "    verbose : bool, optional\n",
    "        If True, passes through to `check_sentiment_value` to print\n",
    "        per-word resolution messages. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        This function modifies `dictionary_name` in place and returns None.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Words are cleaned with `strip().lower()` before insertion.\n",
    "    - Comment lines (prefixed with ';') and blank lines are ignored.\n",
    "    - Conflict resolution is delegated to `check_sentiment_value`.\n",
    "    - ChatGPT assisted in creating this docstring.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> word_dict = {}\n",
    "    >>> create_scoring_dict(word_dict, \"negative-words.txt\", base_value=-1)\n",
    "    >>> create_scoring_dict(word_dict, \"positive-words.txt\", base_value=+1)\n",
    "    >>> word_dict.get(\"terrible\"), word_dict.get(\"great\")\n",
    "    (-1, 1)\n",
    "    \"\"\"\n",
    "    score_value = base_value\n",
    "    with open(text_file_of_words, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            word = line.strip().lower()\n",
    "            if word and not word.startswith(\";\"):\n",
    "                word_score = score_value\n",
    "                if word in dictionary_name:\n",
    "                    word_score = check_sentiment_value(\n",
    "                        word, dictionary_name[word], score_value, verbose\n",
    "                    )\n",
    "                dictionary_name[word] = word_score\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def tidytext_scoring(\n",
    "    dictionary_name, text_file_of_words=\"tidytext_sentiments.txt\", verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Augment a sentiment dictionary using a Tidytext-style lexicon file.\n",
    "\n",
    "    Reads a whitespace-delimited file whose first line is a header and whose\n",
    "    rows contain at least two columns: the token (column 0) and its sentiment\n",
    "    label (column 1). The label \"negative\" is mapped to -1; any other label\n",
    "    is mapped to +1. Each token is lowercased before lookup/insertion. If a\n",
    "    token already exists in `dictionary_name`, conflicts are resolved via\n",
    "    `check_sentiment_value` (e.g., positive vs. negative → set to 0).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dictionary_name : dict[str, int]\n",
    "        Mapping from token to sentiment score. Modified in place. Typical\n",
    "        values are {-1, 0, 1}, where 0 indicates a previously detected conflict.\n",
    "    text_file_of_words : str, optional\n",
    "        Path to the Tidytext-style sentiment file. Must contain a header line\n",
    "        followed by rows with at least \"word\" and \"sentiment\" columns.\n",
    "        Defaults to \"tidytext_sentiments.txt\".\n",
    "    verbose : bool, optional\n",
    "        If True, passes through to `check_sentiment_value` to print per-token\n",
    "        resolution messages. Defaults to False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        The function updates `dictionary_name` in place and returns None.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Assumes whitespace-delimited columns and a single header line (skipped).\n",
    "    - Tokens are normalized with `lower()`.\n",
    "    - Conflict handling is delegated to `check_sentiment_value`.\n",
    "    - ChatGPT assisted in creating this docstring.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> d = {\"great\": 1}\n",
    "    >>> tidytext_scoring(d, \"tidytext_sentiments.txt\")\n",
    "    >>> d.get(\"awful\"), d.get(\"great\")\n",
    "    (-1, 1)\n",
    "    \"\"\"\n",
    "    with open(text_file_of_words, \"r\", encoding=\"utf-8\") as f:\n",
    "        next(f)  # skip header\n",
    "        for line in f:\n",
    "            words = line.split()\n",
    "            if words[1] == \"negative\":\n",
    "                score_value = -1\n",
    "            else:\n",
    "                score_value = 1\n",
    "            word = words[0].lower()\n",
    "            if word in dictionary_name:\n",
    "                score_value = check_sentiment_value(\n",
    "                    word, dictionary_name[word], score_value, verbose\n",
    "                )\n",
    "            dictionary_name[word] = score_value\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def clean_sentiment_dictionary(dictionary_name, conflicting_words_list):\n",
    "    \"\"\"\n",
    "    Remove ambiguous (conflicting) entries from a sentiment dictionary.\n",
    "\n",
    "    This function scans `dictionary_name` for words whose sentiment score is\n",
    "    `0` (used to mark conflicts, e.g., words that appeared in both positive\n",
    "    and negative lists). It removes those words from the dictionary and\n",
    "    appends each removed word to `conflicting_words_list` for auditing or\n",
    "    later review.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dictionary_name : dict[str, int]\n",
    "        Mapping of words to sentiment scores. This dictionary is modified\n",
    "        in place; any key with value `0` is deleted.\n",
    "    conflicting_words_list : list[str]\n",
    "        A list that will be extended with the words removed due to conflict.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        The function performs in-place modifications and prints a short\n",
    "        summary of how many words were removed.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Iterates over a snapshot of keys (`list(dictionary_name.keys())`) to\n",
    "      safely delete items during traversal.\n",
    "    - Use this after building your lexicon to ensure that ambiguous words\n",
    "      don't contribute noise to sentiment scoring.\n",
    "    - ChatGPT assisted in creating this docstring.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> d = {\"happy\": 1, \"sad\": -1, \"sick\": 0}\n",
    "    >>> removed = []\n",
    "    >>> clean_sentiment_dictionary(d, removed)\n",
    "    Total words removed from: 1\n",
    "    >>> d\n",
    "    {'happy': 1, 'sad': -1}\n",
    "    >>> removed\n",
    "    ['sick']\n",
    "    \"\"\"\n",
    "    for key in list(dictionary_name.keys()):\n",
    "        if dictionary_name[key] == 0:\n",
    "            conflicting_words_list.append(key)\n",
    "            del dictionary_name[key]\n",
    "    print(f\"Total words removed from: {len(conflicting_words_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af9e7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the positive and negative words and the\n",
    "# tidytext sentiment. Store these so that the positive\n",
    "# words are associated with a score of +1 and negative words\n",
    "# are associated with a score of -1. You can use a dataframe or a\n",
    "# dictionary for this.\n",
    "pos_score = 1\n",
    "neg_score = -1\n",
    "word_dict = {}\n",
    "conflict_words = []\n",
    "set_verbose = False\n",
    "\n",
    "create_scoring_dict(word_dict, \"negative-words.txt\", neg_score, verbose=set_verbose)\n",
    "create_scoring_dict(word_dict, \"positive-words.txt\", pos_score, verbose=set_verbose)\n",
    "tidytext_scoring(word_dict, verbose=set_verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcbe6fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words removed from: 131\n"
     ]
    }
   ],
   "source": [
    "clean_sentiment_dictionary(word_dict, conflict_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f3b12",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Songs\n",
    "\n",
    "In this section, score the sentiment for all the songs for both artists in your data set. Score the sentiment by manually calculating the sentiment using the combined lexicons provided in this repository.\n",
    "\n",
    "After you have calculated these sentiments, answer the questions at the end of this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664f8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8334f4",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "Q: Overall, which artist has the higher average sentiment per song?\n",
    "\n",
    "A: <!-- Your answer here -->\n",
    "\n",
    "---\n",
    "\n",
    "Q: For your first artist, what are the three songs that have the highest and lowest sentiments? Print the lyrics of those songs to the screen. What do you think is driving the sentiment score?\n",
    "\n",
    "A: <!-- Your answer here -->\n",
    "\n",
    "---\n",
    "\n",
    "Q: For your second artist, what are the three songs that have the highest and lowest sentiments? Print the lyrics of those songs to the screen. What do you think is driving the sentiment score?\n",
    "\n",
    "A: <!-- Your answer here -->\n",
    "\n",
    "---\n",
    "\n",
    "Q: Plot the distributions of the sentiment scores for both artists. You can use `seaborn` to plot densities or plot histograms in matplotlib.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe644d",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Twitter Descriptions\n",
    "\n",
    "In this section, define two sets of emojis you designate as positive and negative. Make sure to have at least 10 emojis per set. You can learn about the most popular emojis on Twitter at [the emojitracker](https://emojitracker.com/).\n",
    "\n",
    "Associate your positive emojis with a score of +1, negative with -1. Score the average sentiment of your two artists based on the Twitter descriptions of their followers. The average sentiment can just be the total score divided by number of followers. You do not need to calculate sentiment on non-emoji content for this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb92eb93",
   "metadata": {},
   "source": [
    "Q: What is the average sentiment of your two artists?\n",
    "\n",
    "A: <!-- Your answer here -->\n",
    "\n",
    "---\n",
    "\n",
    "Q: Which positive emoji is the most popular for each artist? Which negative emoji?\n",
    "\n",
    "A: <!-- Your answer here -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ads509",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
